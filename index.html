<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Orazio Gallo Homepage</title>
    <meta name="author" content="Orazio Gallo">
    <meta name="keywords"
        content="orazio gallo, computer vision, computational imaging, computational photography, image processing">
    <link rel="stylesheet" href="style.css">
</head>

<body>

    <div align="center">

        <div class="title">
            ORAZIO <span style="color: #65AD14">GALLO</span>
        </div>

        <div class="bio">

            <div class="box">
                <p style="margin-bottom:20px">
                    <img class="circularImage" src="imgs/OrazioGallo_crop.jpg" border="1" height="225" align="center">
                </p>
                <a href="mailto:replacethiswithmyfirstname@soe.ucsc.edu"><img src="icons/email.svg" height="30"></a>
                <a href="https://scholar.google.com/citations?user=6UHjQQYAAAAJ&hl=en&oi=ao" target="_blank"><img
                        src="icons/scholar.svg" height=30></a>
                <a href="https://twitter.com/0razio?ref_src=twsrc%5Etfw" target="_blank"><img src="icons/twitter.svg"
                        height="30"></a>
            </div>

            <div class="biohgap"></div>

            <div align="justify">
                I am a Principal Research Scientist and Technical Lead at <a
                    href="https://research.nvidia.com/person/orazio-gallo">NVIDIA Research</a>. I am interested in
                computational imaging, computer vision, deep learning and, in particular, in the intersection of the
                three.</br>
                I am a senior associate editor of the <a
                    href="http://signalprocessingsociety.org/publications-resources/ieee-transactions-computational-imaging">IEEE
                    Transactions on Computational Imaging</a>, and a member of the <a
                    href="http://signalprocessingsociety.org/get-involved/computational-imaging-special-interest-group">IEEE
                    Computational Imaging Technical Committee</a>. From 2015 to 2017 I was an associate editor for
                <a href="https://www.journals.elsevier.com/signal-processing-image-communication">Signal processing:
                    Image Communication</a>.<br><br><br>
                <span style="color: #65AD14">I'm always looking for great interns so reach out to me if you're
                    interested!</span>
            </div>

        </div>

        <div class="sectitle">News</div>

        <div class="textsection">
            <ul>
                <li><img class="scaledImg" src="icons/announce.svg"><span style="color: #65AD14"> I was recognized with
                        an <a href="https://www.bmvc2021-virtualconference.com/people/reviewers/">Outstanding Reviewer
                            Award</a> for BMVC 2021!</li>
                <li><img class="scaledImg" src="icons/announce.svg"><span style="color: #65AD14"> Our paper on visual
                        saliency estimation from incomplete gaze data was accepted at BVMC 2021!</span></li>
                <li>I was recognized with an <a href="https://iccv2021.thecvf.com/outstanding-reviewers">Outstanding
                        Reviewer Award</a>
                    for ICCV 2021!</li>
                <li> Our paper
                    on binary time-to-contact estimation won the <a href="http://cvpr2021.thecvf.com/node/329">Best
                        Student Paper Honorable Mention</a> for CVPR 2021!
                </li>
                <li>I was recognized with an <a href="http://cvpr2021.thecvf.com/node/184">Outstanding Reviewer
                        Award</a> for
                    CVPR 2021!</li>
                <li>Our paper on binary time-to-contact estimation was accepted at CVPR 2021 as an oral!</li>
                <li>Our paper on novel view synthesis from semantic maps was accepted at NeurIPS 2020!</li>
                <li>Our three papers were accepted at CVPR 2020!</li>
                <!-- <li>I will be talking at the <a href="imgs/2019_IMA_CI_workshop.pdf" target="_blank">IMA
                        Workshop on
                        Computational Imaging</a>, I hope to see you there!</li>
                <li>Our paper on novel view synthesis was accepted as an oral presentation at ICCV 2019!</li>
                <li>Our paper on wide-baseline video stitching was accepted at BMVC 2019!</li>
                <li>Our paper on bilateral convolutions for neural networks was accepted at CVPR 2019!</li> -->
                <!-- <li><a href="https://github.com/gorazione/make_supplementary">My script</a> to generate a PDF for
                    comparing the output of different image processing/restoration algorithms (useful for the
                    supplementary material of paper submissions).</li> -->

            </ul>
        </div>

        <div class="sectitle">Professional Service Awards</div>
        <div class="textsection">
            <ul>
                <li><a href="https://photos.app.goo.gl/uapnv8YBy1r4DZ557" target="_blank">Outstanding Editorial Board
                        Member Award</a> for my service to the IEEE Trans. on Comp. Imaging.</li>
                <li>Outstanding Reviewer Award for CVPR 2017, CVPR 2018, CVPR 2021, ICCV 2021, and BMVC 2021!</li>
            </ul>
        </div>

        <div class="sectitle">Talks Available Online</div>
        <div class="textsection">
            <ul>
                <li><a href="https://youtu.be/8h5dJ_Ov2WU" target="_blank">My talk</a> at the <a
                        href="https://sites.google.com/view/sps-space" target="_blank">SPACE</a> seminar on 2020-07-28.
                </li>
                <li><a href="https://youtu.be/OEUHalxanuc" target="_blank">All the talks</a> for our CVPR 2020 tutorial
                    on <a href="https://nvlabs.github.io/nvs-tutorial-cvpr2020/" target="_blank">Novel View
                        Synthesis</a> are available.</li>
                <li>All the talks for our CVPR 2019 tutorial on <a
                        href="https://nvlabs.github.io/dl-for-content-creation/" target="_blank">Deep Learning for
                        Content Creation</a> are available.</li>
            </ul>
            <ul>
            </ul>
        </div>

        <div class="vgap">
        </div>


        <div class="sectitle">Publications</div>

        <div class="paper">
            <a href="https://arxiv.org/abs/2105.05994" target="_blank"><img alt="" src="imgs/dctNerf_icon.gif"
                    height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Neural Trajectory Fields for Dynamic Novel View Synthesis<br>
                <i>Chaoyang Wang, Ben Eckart, Simon Lucey, Orazio Gallo, Arxiv 2021</i>
                <br><i><a href="https://arxiv.org/abs/2105.05994" target="_blank">preprint</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://arxiv.org/abs/2105.05994" target="_blank"><img alt="" src="imgs/tmp.png" height="70"
                    border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Noise-Aware Saliency Prediction for Videos with Incomplete Gaze Data<br>
                <i>Ekta Prashnani, Orazio Gallo, Joohwan Kim, Josef Spjut, Pradeep Sen, Iuri Frosio, BMVC 2021</i>
                <br>
                <i><a href="https://youtu.be/KU4KTlKbH54" target="_blank">teaser video</a></i> and
                <i><a href="https://arxiv.org/abs/2104.08038" target="_blank">paper</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://arxiv.org/abs/2101.04777" target="_blank"><img alt="" src="imgs/bittc.jpg" height="70"
                    border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Binary TTC: A Temporal Geofence for Autonomous Navigation (<a
                    href="http://cvpr2021.thecvf.com/node/329">Best
                    Student Paper Honorable Mention</a>)<br>
                <i>Abhishek Badki, Orazio Gallo, Jan Kautz, Pradeep Sen, CVPR 2021</i>
                <br>
                <i><a href="https://youtu.be/uUQJcjyerM4" target="_blank">teaser video</a>,</i>
                <i><a href="https://github.com/NVlabs/BiTTC" target="_blank">project page (with code)</a>,</i>
                and <i><a href="https://arxiv.org/abs/2101.04777" target="_blank">paper</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://arxiv.org/abs/2008.09106" target="_blank"><img alt="" src="imgs/gvs.gif" height="70"
                    border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Generative View Synthesis: From Single-View Semantics to Novel-View Images<br>
                <i>Tewodros Habtegebrial, Varun Jampani, Orazio Gallo, and Didier Stricker, NeurIPS 2020</i>
                <br>
                <i><a href="https://youtu.be/qz2yX8TIzDk" target="_blank">teaser video</a>,</i>
                <i><a href="https://gvsnet.github.io/" target="_blank">project page</a>,</i>
                <i><a href="https://github.com/tedyhabtegebrial/gvsnet" target="_blank">code</a>,</i>
                and <i><a href="https://arxiv.org/abs/2008.09106" target="_blank">paper</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://github.com/NVlabs/Bi3D" target="_blank"><img alt="" src="imgs/bi3d.png" height="70"
                    border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Bi3D: Stereo Depth Estimation via Binary Classifications<br>
                <i>Abhishek Badki, Alejandro Troccoli, Kihwan Kim, Jan Kautz, Pradeep Sen, and Orazio Gallo,
                    CVPR 2020</i><br>
                <i><a href="https://youtu.be/HuEwjpw5O64" target="_blank">teaser video</a>,</i>
                <i><a href="https://github.com/NVlabs/Bi3D" target="_blank">project page (with code)</a>,</i>
                and <i><a href="https://arxiv.org/abs/2005.07274" target="_blank">paper</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2020-06_Dynamic-Scene-View" target="_blank"><img alt=""
                    src="imgs/dynamic_nvs.png" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Novel View Synthesis of Dynamic Scenes with Globally Coherent Depths from a Monocular Camera<br>
                <i>Jae Shin Yoon, Kihwan Kim, Orazio Gallo, Hyun Soo Park, and Jan Kautz,
                    CVPR 2020</i><br>
                <i><a href="https://youtu.be/S8_0V3fZIes" target="_blank">teaser video</a>,</i>
                <i><a href="https://research.nvidia.com/publication/2020-06_Dynamic-Scene-View" target="_blank">project
                        page</a>,</i>
                and <i><a href="https://arxiv.org/abs/2004.01294" target="_blank">paper</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2020-06_Meshlet-Priors-for" target="_blank"><img alt=""
                    src="imgs/meshlets.png" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Meshlet Priors for 3D Mesh Reconstruction<br>
                <i>Abhishek Badki, Orazio Gallo, Jan Kautz, and Pradeep Sen,
                    CVPR 2020</i><br>
                <i><a href="https://youtu.be/glZyJ66ktog" target="_blank">teaser video</a>,</i> <i><a
                        href="https://research.nvidia.com/publication/2020-06_Meshlet-Priors-for"
                        target="_blank">project
                        page</a>,</i>
                and <i><a href="https://arxiv.org/abs/2001.01744" target="_blank">paper</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-08_Extreme-View-Synthesis" target="_blank"><img alt=""
                    src="imgs/evs.gif" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Extreme View Synthesis<br>
                <i>Inchang Choi, Orazio Gallo, Alejandro Troccoli, Min H. Kim, and Jan Kautz, ICCV 2019</i>
                (<i>oral</i>)<br>
                <a href="https://developer.nvidia.com/gtc/2019/video/S9576" target="_blank">GTC 2019 talk</a>, and
                <i><a href="https://research.nvidia.com/publication/2019-08_Extreme-View-Synthesis"
                        target="_blank">project
                        page</a> (with <a href="https://github.com/NVlabs/extreme-view-synth"
                        target="_blank">code</a>).</i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-09_Video-Stitching-for" target="_blank"><img alt=""
                    src="imgs/stitching.jpg" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Video Stitching for Linear Camera Arrays<br>
                <i>Wei-Sheng (Jason) Lai, Orazio Gallo, Jinwei Gu, Deqing Sun, Ming-Hsuan Yang, and Jan Kautz, BMVC
                    2019</i><br>
                <i><a href="https://research.nvidia.com/publication/2019-09_Video-Stitching-for" target="_blank">project
                        page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-06_Pixel-Adaptive-Convolutional-Neural"><img alt=""
                    src="imgs/pacnet.png" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Pixel-Adaptive Convolutional Neural Networks<br>
                <i>Hang Su, Varun Jampani, Deqing Sun, Orazio Gallo, Erik-Learned Miller, and Jan Kautz, CVPR
                    2019</i><br>
                <i><a href="https://research.nvidia.com/publication/2019-06_Pixel-Adaptive-Convolutional-Neural">project
                        page</a> (with <a href="https://github.com/NVlabs/pacnet">code</a>)</i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-01_A-Fusion-Approach"><img alt="" src="imgs/tmp.png"
                    height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                A Fusion Approach for Multi-Frame Optical Flow Estimation<br>
                <i>Zhile Ren, Orazio Gallo, Deqing Sun, Ming-Hsuan Yang, Erik B. Sudderth, and Jan Kautz, WACV
                    2019</i><br>
                <i><a href="https://research.nvidia.com/publication/2019-01_A-Fusion-Approach">project page</a>
                    (with <a href="https://github.com/NVlabs/PWC-Net/tree/master/Multi_Frame_Flow">code</a>)</i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2018-09_Separating-Reflection-and"><img alt=""
                    src="imgs/reflections.jpg" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Separating Reflection and Transmission Images in the Wild<br>
                <i>Patrick Wieschollek, Orazio Gallo, Jinwei Gu, and Jan Kautz, ECCV 2018</i><br>
                <i><a href="https://research.nvidia.com/publication/2018-09_Separating-Reflection-and">project
                        page</a> (with <a href="https://github.com/NVlabs/ReflectNet">code</a>)</i>
            </div>
        </div>

        <div class="paper">
            <a href="http://alumni.soe.ucsc.edu/~orazio"><img alt="" src="imgs/FLAT.jpg" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Tackling 3D ToF Artifacts Through Learning and the FLAT Dataset<br>
                <i>Qi Guo, Iuri Frosio, Orazio Gallo, Todd Zickler, and Jan Kautz, ECCV 2018</i><br>
                <i><a href="https://research.nvidia.com/publication/2018-09_Tackling-3D-ToF">project page</a> (with
                    <a href="https://github.com/NVlabs/FLAT">code</a>)</i>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/publication/2018-05_Reblur2Deblur%3A-Deblurring-Videos"><img alt=""
                    src="imgs/reblur.gif" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Reblur2Deblur: Deblurring Videos via Self-Supervised Learning<br>
                <i>Huaijin Chen, Jinwei Gu, Orazio Gallo, Ming-Yu Liu, Ashok Veeraraghavan, and Jan Kautz, ICCP
                    2018</i><br>
                <i><a href="http://research.nvidia.com/publication/2018-05_Reblur2Deblur%3A-Deblurring-Videos">project
                        page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://cvc.ucsb.edu/graphics/Papers/SIGGRAPH2017_ComputationalZoom/"><img alt=""
                    src="imgs/compzoom.png" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Computational Zoom: A Framework for Post-Capture Image Composition<br>
                <i>Abhishek Badki, Orazio Gallo, Jan Kautz, and Pradeep Sen, SIGGRAPH 2017</i>><br>
                <i><a href="http://cvc.ucsb.edu/graphics/Papers/SIGGRAPH2017_ComputationalZoom/">project
                        page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/publication/loss-functions-image-restoration-neural-networks"><img
                    alt="" src="imgs/losses.jpg" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Loss Functions for Image Restoration with Neural Networks<br>
                <i>Hang Zhao, Orazio Gallo, Iuri Frosio, and Jan Kautz, IEEE Transactions on Computational Imaging,
                    2017</i><br>
                <i><a href="http://research.nvidia.com/publication/loss-functions-image-restoration-neural-networks">project
                        page</a> (with <a href="https://github.com/NVlabs/PL4NN">code</a>)</i>
            </div>
        </div>

        <div class="paper">
            <a
                href="http://research.nvidia.com/publication/reconstructing-intensity-images-binary-spatial-gradient-cameras"><img
                    alt="" src="imgs/graincam2.jpg" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Reconstructing Intensity Images from Binary Spatial Gradient Cameras<br>
                <i>Suren Jayasuriya, Orazio Gallo, Jinwei Gu, Timo Aila, and Jan Kautz, Embedded Vision Workshop, CVPR
                    2017</i><br>
                <i><a
                        href="http://research.nvidia.com/publication/reconstructing-intensity-images-binary-spatial-gradient-cameras">project
                        page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/stack-based-algorithms-hdr-capture-and-reconstruction"><img
                    alt="" src="imgs/bookCover.jpg" height="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Stack-Based Algorithms for HDR Capture and Reconstruction<br>
                <i>Orazio Gallo and Pradeep Sen, Chapter in "High Dynamic Range Video: From Acquisition, to Display and
                    Applications," Academic Press, 2016</i><br>
                <i><a
                        href="http://research.nvidia.com/sites/default/files/publications/Gallo-Sen_StackBasedHDR_2016.pdf">pdf</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://graphics.stanford.edu/papers/gazehdr/"><img alt="" src="imgs/ToG15_icon.gif" height="70"
                    width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Simulating the Visual Experience of Very Bright and Very Dark Scenes<br>
                <i>David Jacobs, Orazio Gallo, Emily Cooper, Kari Pulli, and Marc Levoy, Transactions on Graphics,
                    2015</i><br>
                <i><a href="http://graphics.stanford.edu/papers/gazehdr/">project page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/locally-non-rigid-registration-mobile-hdr-photography"><img
                    alt="" src="imgs/FastNRR.jpg" height="70" width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Locally Non-rigid Registration for Mobile HDR Photography<br>
                <i>Orazio Gallo, Alejandro Troccoli, Jun Hu, Kari Pulli, and Jan Kautz, Embedded Vision Workshop, CVPR
                    2015</i><br>
                <i><a
                        href="http://research.nvidia.com/publication/locally-non-rigid-registration-mobile-hdr-photography">project
                        page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/sites/default/files/publications/GalloEtAl_GrayHDR_CVPRW15.pdf"><img
                    alt="" src="imgs/GrayCam_icon.jpg" height="70" width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Retrieving Gray-Level Information from a Binary Sensor and its Application to Gesture
                Detection<br>
                <i>Orazio Gallo, Iuri Frosio, Leonardo Gasparini, Kari Pulli, and Massimo Gottardi, Embedded Vision
                    Workshop, CVPR
                    2015</i><br>
                <i><a
                        href="http://research.nvidia.com/sites/default/files/pubs/2015-06_Retrieving-Gray-Level-Information/GalloEtAl_GrayHDR_CVPRW15.pdf">pdf</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/publication/flexisp-flexible-camera-image-processing-framework"><img
                    alt="" src="imgs/flexIsp_icon.png" height="70" width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                FlexISP: A Flexible Camera Image Processing Framework<br>
                <!-- <p style="font-size: 15"> -->
                <i>F. Heide, M. Steinberger, Y. Tsai, M. Rouf, D. Pajak, D. Reddy, O. Gallo, J. Liu, W. Heidrich, K.
                    Egiazarian, J. Kautz, K. Pulli, SIGGRAPH ASIA 2014</i><br>
                <i><a href="https://research.nvidia.com/publication/flexisp-flexible-camera-image-processing-framework">project
                        page</a></i>
                <!-- </p> -->

            </div>
        </div>

        <div class="paper">
            <a href="http://graphics.stanford.edu/papers/dynamicstacks/"><img alt="" src="imgs/cvpr14_icon.gif"
                    height="70" width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Dynamic Image Stacks<br>
                <i>David Jacobs, Orazio Gallo, and Kari Pulli, Workshop on Mobile Vision, CVPR 2014</i><br>
                <i><a href="http://graphics.stanford.edu/papers/dynamicstacks/">project page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://www.cs.duke.edu/~junhu/CVPR2013/"><img alt="" src="imgs/cvpr13_icon.gif" height="70"
                    width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                HDR Deghosting: How to deal with Saturation?<br>
                <i>Jun Hu, Orazio Gallo, Kari Pulli, and Xiaobai Sun, CVPR 2013</i><br>
                <i><a href="http://www.cs.duke.edu/~junhu/CVPR2013/">project page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://alumni.soe.ucsc.edu/~orazio/hdr_metering.html"><img alt="" src="imgs/Metering_Icon.jpg"
                    height="70" width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Metering for Exposure Stacks<br>
                <i>Orazio Gallo, Marius Tico, Roberto Manduchi, Natasha Gelfand, and Kari Pulli, Eurographics
                    2012</i><br>
                <i><a href="http://alumni.soe.ucsc.edu/~orazio/hdr_metering.html">project page</a></i>
            </div>
        </div>

        <div class="paper">
            <a href="http://alumni.soe.ucsc.edu/~orazio/ExposureStacks.html"><img alt="" src="imgs/eccv12_icon.gif"
                    height="70" width="70" border="1"></a>
            <div class="paperhgap"></div>
            <div class="papertitle">
                Exposure Stacks for Live Scenes with Hand-held Cameras<br>
                <i>Jun Hu, Orazio Gallo, and Kari Pulli, ECCV 2012</i><br>
                <i><a href="http://alumni.soe.ucsc.edu/~orazio/ExposureStacks.html">project page</a></i>
            </div>
        </div>

        <div class="sectitle">Older Publications</div>

        <div class="textsection">
            <ul>
                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/papers/GalloCCRansac_PRL11.pdf">CC-RANSAC: Fitting
                        Planes in the Presence of Multiple Surfaces in Range Data</a>, O. Gallo, R. Manduchi,
                    and A. Rafii, Pattern Recognition Letters, 2011
                </li>

                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/barcodes.html">Reading 1-D Barcodes with Mobile
                        Phones Using Deformable Templates</a>, O. Gallo and R. Manduchi, IEEE TPAMI, 2011
                </li>

                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/DavisACVHL_CVPR10.pdf">The HPU</a>,
                    J. Davis, J. Arderiu, H. Lin, Z. Nevins, S. Schuon, O. Gallo, and M. Yang, Worshop on Computer
                    Vision with Humans in the Loop, CVPR 2010
                </li>

                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/barcodes.html">Reading Challenging Barcodes with
                        Cameras</a>, O. Gallo and R. Manduchi, IEEE WACV 2009
                </li>

                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/deghost.html">Artifact-free High Dynamic Range
                        Imaging</a>, O. Gallo, N. Gelfand, W. Chen, M. Tico, and K. Pulli, ICCP 2009
                </li>

                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/papers/GalloCCRansac_PRL11.pdf">Robust Curb and Ramp
                        Detection for Safe Parking Using the Canesta TOF Camera</a>, O. Gallo, R. Manduchi, and
                    A. Rafii, Workshop on Time-of-Flight-based Computer Vision, CVPR 2008
                </li>

                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/demoICIP08.html">A Camera-Based Pointing Interface
                        for Mobile Devices</a>, O. Gallo, S. Arteaga, and J. E. Davis, ICIP 2008
                </li>

                <li> <a href="http://jov.arvojournals.org/article.aspx?articleid=2121969">Stability of Gold Bead
                        Tissue Markers</a>, J. Miller, E. Rossi, M. Wiesmair, D. Alexander, and O. Gallo,
                    Journal of Vision, 2006
                </li>

                <li> <a href="http://alumni.soe.ucsc.edu/~orazio/papers/hROIsComb.pdf">Combining Conspicuity Maps for
                        hROIs Prediction</a>, C. Privitera, O. Gallo, G. Grimoldi, T. Fujita, and L. Stark,
                    Workshop on Attention and Performance in Computational Vision, ECCV 2004
                </li>

            </ul>
        </div>
        <div class="vgap">
        </div>

    </div>

    <script type="text/javascript">
        var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." :
            "http://www.");
        document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>

    <script type="text/javascript">
        var pageTracker = _gat._getTracker("UA-3369655-1");
        pageTracker._initData();
        pageTracker._trackPageview();
    </script>

</body>

</html>