<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Orazio Gallo Homepage</title>
    <meta name="author" content="Orazio Gallo">
    <meta name="keywords"
        content="orazio gallo, computer vision, computational imaging, computational photography, image processing">
    <link rel="stylesheet" href="og_style.css">
    <link rel="stylesheet" media="screen" href="https://fontlibrary.org/face/linux-libertine" type="text/css" />
</head>

<body>

    <div align="center">
        <div class="title">
            <h1>ORAZIO <span style="color: #65AD14">GALLO</span></h1>
        </div>
        <div class="bio">
            <img class="circularImage" src="imgs/OrazioGallo_crop.jpg" border="1" height="250" align="left">
            <div class="biohgap">
            </div>
            <div align="justify">
                <span>
                    I am a Principal Research Scientist and technical lead at <a
                        href="https://research.nvidia.com/person/orazio-gallo">NVIDIA Research</a>. I am interested in
                    computational imaging, computer vision, deep learning and, in particular, in the intersection of the
                    three. Alongside topics such as view synthesis and 3D vision, my recent interests also include
                    integrating traditional computer vision and computational imaging knowledge into deep learning
                    architectures. I am also an associate editor of the <a
                        href="http://signalprocessingsociety.org/publications-resources/ieee-transactions-computational-imaging">IEEE
                        Transactions on Computational Imaging</a>, and a member of the <a
                        href="http://signalprocessingsociety.org/get-involved/computational-imaging-special-interest-group">IEEE
                        Computational Imaging Technical Committee</a>. From 2015 to 2017 I was an associate editor for
                    <a href="https://www.journals.elsevier.com/signal-processing-image-communication">Signal processing:
                        Image Communication</a>.

                    I received my Ph.D. in Computer Engineering from the University of California, Santa Cruz in 2011,
                    and my Masters in Biomedical Engineering from Politecnico di Milano, Italy.<br><br>

                    <span style="color: #65AD14">I'm always looking for great interns so reach out to me if you're
                        interested!</span><br><br>

                    <a href="mailto:replacethiswithmyfirstname@soe.ucsc.edu"><img src="icons/email.svg" height="30"></a>
                    <a href="https://scholar.google.com/citations?user=6UHjQQYAAAAJ&hl=en&oi=ao" target="_blank"><img
                            src="icons/scholar.svg" height=30></a>
                    <a href="https://twitter.com/0razio?ref_src=twsrc%5Etfw" target="_blank"><img
                            src="icons/twitter.svg" height="30"></a>
                </span>
            </div>
        </div>

        <div class="vgap">
        </div>

        <div class="sectitle">
            <h2>News</h2>
        </div>
        <div class="textsection">
            <ul>
                <li>Our paper on novel view synthesis from semantic maps was accepted at NeurIPS 2020!
                <li>Our three papers were accepted at CVPR 2020!
                <li>I will be talking at the <a href="imgs/2019_IMA_CI_workshop.pdf" target="_blank">IMA Workshop on
                        Computational Imaging</a>, I hope to see you there!</li>
                <li>Our paper on novel view synthesis was accepted as an oral presentation at ICCV 2019!</li>
                <li>Our paper on wide-baseline video stitching was accepted at BMVC 2019!</li>
                <li>Our paper on bilateral convolutions for neural networks was accepted at CVPR 2019!</li>
                <!-- <li><a href="https://github.com/gorazione/make_supplementary">My script</a> to generate a PDF for
                    comparing the output of different image processing/restoration algorithms (useful for the
                    supplementary material of paper submissions).</li> -->

            </ul>
        </div>

        <div class="sectitle">
            <h2>Professional Service Awards</h2>
        </div>
        <div class="textsection">
            <ul>
                <li><a href="https://photos.app.goo.gl/uapnv8YBy1r4DZ557" target="_blank">Outstanding Editorial Board
                        Member Award</a>
                    for my service to the IEEE Trans. on
                    Comp. Imaging.</li>
                <li>Outstanding Reviewer Award for CVPR 2017 and CVPR 2018!</li>
            </ul>
        </div>

        <div class="sectitle">
            <h2>Talks Available Online</h2>
        </div>
        <div class="textsection">
            <ul>
                <li><a href="https://youtu.be/8h5dJ_Ov2WU" target="_blank">My talk</a> at the <a
                        href="https://sites.google.com/view/sps-space" target="_blank">SPACE</a> seminar on 2020-07-28.
                </li>
                <li><a href="https://youtu.be/OEUHalxanuc" target="_blank">All the talks</a> for our CVPR 2020 tutorial
                    on <a href="https://nvlabs.github.io/nvs-tutorial-cvpr2020/" target="_blank">Novel View
                        Synthesis</a>
                    are available.</li>
                <li>All the talks for our CVPR 2019 tutorial on <a
                        href="https://nvlabs.github.io/dl-for-content-creation/" target="_blank">Deep Learning for
                        Content Creation</a> are available.</li>
            </ul>
            <ul>
            </ul>
        </div>

        <div class="vgap">
        </div>


        <div class="sectitle">
            <h2>Publications</h2>
        </div>

        <div class="paper">
            <a href="https://arxiv.org/abs/2008.09106" target="_blank"><img alt="" src="imgs/tmp.png" height="70"
                    border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Generative View Synthesis: From Single-View Semantics to Novel-View Images</b>,
                    Tewodros Habtegebrial, Varun Jampani, Orazio Gallo, and Didier Stricker, NeurIPS 2020
                    <br>
                    <i><a href="https://arxiv.org/abs/2008.09106" target="_blank">preprint</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://github.com/NVlabs/Bi3D" target="_blank"><img alt="" src="imgs/tmp.png" height="70"
                    border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Bi3D: Stereo Depth Estimation via Binary Classifications</b>,
                    Abhishek Badki, Alejandro Troccoli, Kihwan Kim, Jan Kautz, Pradeep Sen, and Orazio Gallo,
                    CVPR 2020<br>
                    <i><a href="https://youtu.be/HuEwjpw5O64" target="_blank">teaser video</a>,</i>
                    <i><a href="https://github.com/NVlabs/Bi3D" target="_blank">project page (with code)</a></i>
                    and <i><a href="https://arxiv.org/abs/2005.07274" target="_blank">paper</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2020-06_Dynamic-Scene-View" target="_blank"><img alt=""
                    src="imgs/tmp.png" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Novel View Synthesis of Dynamic Scenes with Globally Coherent Depths from a Monocular Camera</b>,
                    Jae Shin Yoon, Kihwan Kim, Orazio Gallo, Hyun Soo Park, and Jan Kautz,
                    CVPR 2020<br>
                    <i><a href="https://youtu.be/S8_0V3fZIes" target="_blank">teaser video</a>,</i>
                    <i><a href="https://research.nvidia.com/publication/2020-06_Dynamic-Scene-View"
                            target="_blank">project
                            page</a>,</i>
                    and <i><a href="https://arxiv.org/abs/2004.01294" target="_blank">paper</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2020-06_Meshlet-Priors-for" target="_blank"><img alt=""
                    src="imgs/tmp.png" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Meshlet Priors for 3D Mesh Reconstruction</b>,
                    Abhishek Badki, Orazio Gallo, Jan Kautz, and Pradeep Sen,
                    CVPR 2020<br>
                    <i><a href="https://youtu.be/glZyJ66ktog" target="_blank">teaser video</a>,</i> <i><a
                            href="https://research.nvidia.com/publication/2020-06_Meshlet-Priors-for"
                            target="_blank">project
                            page</a>,</i>
                    and <i><a href="https://arxiv.org/abs/2001.01744" target="_blank">paper</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-08_Extreme-View-Synthesis" target="_blank"><img alt=""
                    src="imgs/evs.gif" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Extreme View Synthesis</b>,
                    Inchang Choi, Orazio Gallo, Alejandro Troccoli, Min H. Kim, and Jan Kautz, ICCV 2019
                    (<i>oral</i>)<br>
                    <a href="https://developer.nvidia.com/gtc/2019/video/S9576" target="_blank">GTC 2019 talk</a>, and
                    <i><a href="https://research.nvidia.com/publication/2019-08_Extreme-View-Synthesis"
                            target="_blank">project
                            page</a> (with <a href="https://github.com/NVlabs/extreme-view-synth"
                            target="_blank">code</a>).</i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-09_Video-Stitching-for" target="_blank"><img alt=""
                    src="imgs/stitching.jpg" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Video Stitching for Linear Camera Arrays</b>,
                    Wei-Sheng (Jason) Lai, Orazio Gallo, Jinwei Gu, Deqing Sun, Ming-Hsuan Yang, and Jan Kautz, BMVC
                    2019<br>
                    <i><a href="https://research.nvidia.com/publication/2019-09_Video-Stitching-for"
                            target="_blank">project
                            page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-06_Pixel-Adaptive-Convolutional-Neural"><img alt=""
                    src="imgs/pacnet.png" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Pixel-Adaptive Convolutional Neural Networks</b>,
                    Hang Su, Varun Jampani, Deqing Sun, Orazio Gallo, Erik-Learned Miller, and Jan Kautz, CVPR 2019<br>
                    <i><a href="https://research.nvidia.com/publication/2019-06_Pixel-Adaptive-Convolutional-Neural">project
                            page</a> (with <a href="https://github.com/NVlabs/pacnet">code</a>)</i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2019-01_A-Fusion-Approach"><img alt="" src="imgs/tmp.png"
                    height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>A Fusion Approach for Multi-Frame Optical Flow Estimation</b>,
                    Zhile Ren, Orazio Gallo, Deqing Sun, Ming-Hsuan Yang, Erik B. Sudderth, and Jan Kautz, WACV 2019<br>
                    <i><a href="https://research.nvidia.com/publication/2019-01_A-Fusion-Approach">project page</a>
                        (with <a href="https://github.com/NVlabs/PWC-Net/tree/master/Multi_Frame_Flow">code</a>)</i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/2018-09_Separating-Reflection-and"><img alt=""
                    src="imgs/reflections.jpg" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Separating Reflection and Transmission Images in the Wild</b>,
                    P. Wieschollek, O. Gallo, J. Gu, and J. Kautz, ECCV 2018<br>
                    <i><a href="https://research.nvidia.com/publication/2018-09_Separating-Reflection-and">project
                            page</a> (with <a href="https://github.com/NVlabs/ReflectNet">code</a>)</i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://alumni.soe.ucsc.edu/~orazio"><img alt="" src="imgs/FLAT.jpg" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Tackling 3D ToF Artifacts Through Learning and the FLAT Dataset</b>,
                    Q. Guo, I. Frosio, O. Gallo, T. Zickler, and J. Kautz, ECCV 2018<br>
                    <i><a href="https://research.nvidia.com/publication/2018-09_Tackling-3D-ToF">project page</a> (with
                        <a href="https://github.com/NVlabs/FLAT">code</a>)</i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/publication/2018-05_Reblur2Deblur%3A-Deblurring-Videos"><img alt=""
                    src="imgs/reblur.gif" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Reblur2Deblur: Deblurring Videos via Self-Supervised Learning</b>,
                    H. Chen, J. Gu, O. Gallo, M. Liu, A. Veeraraghavan, and J. Kautz, IEEE ICCP 2018<br>
                    <i><a href="http://research.nvidia.com/publication/2018-05_Reblur2Deblur%3A-Deblurring-Videos">project
                            page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://cvc.ucsb.edu/graphics/Papers/SIGGRAPH2017_ComputationalZoom/"><img alt=""
                    src="imgs/compzoom.png" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Computational Zoom: A Framework for Post-Capture Image Composition</b>,
                    A. Badki, O. Gallo, J. Kautz, and P. Sen, ACM SIGGRAPH 2017<br>
                    <i><a href="http://cvc.ucsb.edu/graphics/Papers/SIGGRAPH2017_ComputationalZoom/">project
                            page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/publication/loss-functions-image-restoration-neural-networks"><img
                    alt="" src="imgs/losses.jpg" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Loss Functions for Image Restoration with Neural Networks</b>,
                    H. Zhao, O. Gallo, I. Frosio, and J. Kautz, IEEE Transactions on Computational Imaging, 2017<br>
                    <i><a
                            href="http://research.nvidia.com/publication/loss-functions-image-restoration-neural-networks">project
                            page</a> (with <a href="https://github.com/NVlabs/PL4NN">code</a>)</i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a
                href="http://research.nvidia.com/publication/reconstructing-intensity-images-binary-spatial-gradient-cameras"><img
                    alt="" src="imgs/graincam2.jpg" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Reconstructing Intensity Images from Binary Spatial Gradient Cameras</b>,
                    S. Jayasuriya, O. Gallo, J. Gu, T. Aila, and J. Kautz, Embedded Vision Workshop, CVPR 2017<br>
                    <i><a
                            href="http://research.nvidia.com/publication/reconstructing-intensity-images-binary-spatial-gradient-cameras">project
                            page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/stack-based-algorithms-hdr-capture-and-reconstruction"><img
                    alt="" src="imgs/bookCover.jpg" height="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Stack-Based Algorithms for HDR Capture and Reconstruction</b>,
                    O. Gallo and P. Sen, Chapter in the book "High Dynamic Range Video: From Acquisition, to Display and
                    Applications," Academic Press, 2016<br>
                    <i><a
                            href="http://research.nvidia.com/sites/default/files/publications/Gallo-Sen_StackBasedHDR_2016.pdf">pdf</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://graphics.stanford.edu/papers/gazehdr/"><img alt="" src="imgs/ToG15_icon.gif" height="70"
                    width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Simulating the Visual Experience of Very Bright and Very Dark Scenes</b>,
                    D. Jacobs, O. Gallo, E. Cooper, K. Pulli, and M. Levoy, ACM Transactions on Graphics, 2015<br>
                    <i><a href="http://graphics.stanford.edu/papers/gazehdr/">project page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="https://research.nvidia.com/publication/locally-non-rigid-registration-mobile-hdr-photography"><img
                    alt="" src="imgs/FastNRR.jpg" height="70" width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Locally Non-rigid Registration for Mobile HDR Photography</b>,
                    O. Gallo, A. Troccoli, J. Hu, K. Pulli, and J. Kautz, Embedded Vision Workshop, CVPR 2015<br>
                    <i><a
                            href="http://research.nvidia.com/publication/locally-non-rigid-registration-mobile-hdr-photography">project
                            page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/sites/default/files/publications/GalloEtAl_GrayHDR_CVPRW15.pdf"><img
                    alt="" src="imgs/GrayCam_icon.jpg" height="70" width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Retrieving Gray-Level Information from a Binary Sensor and its Application to Gesture
                        Detection</b>,
                    O. Gallo, I. Frosio, L. Gasparini, K. Pulli, and M. Gottardi, Embedded Vision Workshop, CVPR
                    2015<br>
                    <i><a
                            href="http://research.nvidia.com/sites/default/files/pubs/2015-06_Retrieving-Gray-Level-Information/GalloEtAl_GrayHDR_CVPRW15.pdf">pdf</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://research.nvidia.com/publication/flexisp-flexible-camera-image-processing-framework"><img
                    alt="" src="imgs/flexIsp_icon.png" height="70" width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>FlexISP: A Flexible Camera Image Processing Framework</b>,
                    F. Heide, M. Steinberger, Y. Tsai, M. Rouf, D. Pajak, D. Reddy, O. Gallo, J. Liu, W. Heidrich, K.
                    Egiazarian, J. Kautz, and K. Pulli, ACM SIGGRAPH ASIA 2014<br>
                    <i><a
                            href="https://research.nvidia.com/publication/flexisp-flexible-camera-image-processing-framework">project
                            page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://graphics.stanford.edu/papers/dynamicstacks/"><img alt="" src="imgs/cvpr14_icon.gif"
                    height="70" width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Dynamic Image Stacks</b>,
                    D. Jacobs, O. Gallo, and K. Pulli, Workshop on Mobile Vision, CVPR 2014<br>
                    <i><a href="http://graphics.stanford.edu/papers/dynamicstacks/">project page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://www.cs.duke.edu/~junhu/CVPR2013/"><img alt="" src="imgs/cvpr13_icon.gif" height="70"
                    width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>HDR Deghosting: How to deal with Saturation?</b>,
                    J. Hu, O. Gallo, K. Pulli, and X. Sun, CVPR 2013<br>
                    <i><a href="http://www.cs.duke.edu/~junhu/CVPR2013/">project page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://alumni.soe.ucsc.edu/~orazio/hdr_metering.html"><img alt="" src="imgs/Metering_Icon.jpg"
                    height="70" width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Metering for Exposure Stacks</b>,
                    O. Gallo, M. Tico, R. Manduchi, N. Gelfand, and K. Pulli, Eurographics 2012<br>
                    <i><a href="http://alumni.soe.ucsc.edu/~orazio/hdr_metering.html">project page</a></i>
                </span>
            </div>
        </div>

        <div class="paper">
            <a href="http://alumni.soe.ucsc.edu/~orazio/ExposureStacks.html"><img alt="" src="imgs/eccv12_icon.gif"
                    height="70" width="70" border="1"></a>
            <div class="paperhgap">
            </div>
            <div align="left">
                <span>
                    <b>Exposure Stacks for Live Scenes with Hand-held Cameras</b>,
                    J. Hu, O. Gallo, and K. Pulli, ECCV 2012<br>
                    <i><a href="http://alumni.soe.ucsc.edu/~orazio/ExposureStacks.html">project page</a></i>
                </span>
            </div>
        </div>

        <div class="sectitle">
            <h2>Publications (before 2012)</h2>
        </div>

        <div class="textsection">
            <ul>
                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/papers/GalloCCRansac_PRL11.pdf">CC-RANSAC: Fitting
                            Planes in the Presence of Multiple Surfaces in Range Data</a></b>, O. Gallo, R. Manduchi,
                    and A. Rafii, Pattern Recognition Letters, 2011
                </li>

                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/barcodes.html">Reading 1-D Barcodes with Mobile
                            Phones Using Deformable Templates</a></b>, O. Gallo and R. Manduchi, IEEE TPAMI, 2011
                </li>

                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/DavisACVHL_CVPR10.pdf">The HPU</a></b>,
                    J. Davis, J. Arderiu, H. Lin, Z. Nevins, S. Schuon, O. Gallo, and M. Yang, Worshop on Computer
                    Vision with Humans in the Loop, CVPR 2010
                </li>

                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/barcodes.html">Reading Challenging Barcodes with
                            Cameras</a></b>, O. Gallo and R. Manduchi, IEEE WACV 2009
                </li>

                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/deghost.html">Artifact-free High Dynamic Range
                            Imaging</a></b>, O. Gallo, N. Gelfand, W. Chen, M. Tico, and K. Pulli, ICCP 2009
                </li>

                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/papers/GalloCCRansac_PRL11.pdf">Robust Curb and Ramp
                            Detection for Safe Parking Using the Canesta TOF Camera</a></b>, O. Gallo, R. Manduchi, and
                    A. Rafii, Workshop on Time-of-Flight-based Computer Vision, CVPR 2008
                </li>

                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/demoICIP08.html">A Camera-Based Pointing Interface
                            for Mobile Devices</a></b>, O. Gallo, S. Arteaga, and J. E. Davis, ICIP 2008
                </li>

                <li> <b><a href="http://jov.arvojournals.org/article.aspx?articleid=2121969">Stability of Gold Bead
                            Tissue Markers</a></b>, J. Miller, E. Rossi, M. Wiesmair, D. Alexander, and O. Gallo,
                    Journal of Vision, 2006
                </li>

                <li> <b><a href="http://alumni.soe.ucsc.edu/~orazio/papers/hROIsComb.pdf">Combining Conspicuity Maps for
                            hROIs Prediction</a></b>, C. Privitera, O. Gallo, G. Grimoldi, T. Fujita, and L. Stark,
                    Workshop on Attention and Performance in Computational Vision, ECCV 2004
                </li>

            </ul>
        </div>
        <div class="vgap">
        </div>

    </div>

    <script type="text/javascript">
        var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." :
            "http://www.");
        document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>

    <script type="text/javascript">
        var pageTracker = _gat._getTracker("UA-3369655-1");
        pageTracker._initData();
        pageTracker._trackPageview();
    </script>

</body>

</html>